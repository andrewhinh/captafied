Repos,Stars,Forks,"Release Year",Icons,Summary
Transformers,76000,17200,2020,./backend/inference/tests/support/images/0.png,"Transformers provides thousands of pretrained models to perform tasks on different modalities such as text, vision, and audio."
Tapas,894,184,2020,./backend/inference/tests/support/images/1.png,"TAble PArSing (TAPAS)"
CLIP,11200,1700,2021,./backend/inference/tests/support/images/2.png,"CLIP (Contrastive Language-Image Pre-Training) is a neural network trained on a variety of (image, text) pairs."