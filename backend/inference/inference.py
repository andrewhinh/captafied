# Imports
import json
import os
from pathlib import Path
import tempfile
import traceback
from typing import List, Optional

from backend.util import encode_b64_image, open_image, read_b64_image
import boto3
from botocore import UNSIGNED
from botocore.config import Config
from dotenv import load_dotenv
import numpy as np
import openai
import pandas as pd
import plotly
import plotly.io as pio
import requests as rq
from tenacity import retry, stop_after_attempt, wait_random_exponential
import validators
from ydata_profiling import ProfileReport

# Setup
load_dotenv()

pio.templates.default = "plotly_dark"
openai.api_key = os.getenv("OPENAI_API_KEY")

write_bucket = "captafied-ydata-report"
asset_path = Path("assets")
report_name = "report.html"
s3 = boto3.client("s3", config=Config(signature_version=UNSIGNED))


# Classes
class InvalidRequest(ValueError):
    """Raise this when an invalid request is made to the API"""


class Pipeline:
    """
    Main inference class
    """

    def __init__(self):
        # OpenAI params
        self.model = "gpt-4"
        self.temperature = 0.0
        self.max_chars = int(
            4096 * 4
        )  # https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them
        self.max_answer_chars = int(self.max_chars / 8)  # 2048 chars
        self.max_answer_tokens = int(self.max_answer_chars / 4)  # 512 tokens
        self.max_prompt_chars = int(self.max_chars - self.max_answer_chars)  # Remaining chars
        self.data_types = [
            "text string",
            "image path or URL",
            "categorical",
            "continuous",
        ]  # Context for system message

        # Outputs
        self.result = []
        self.outputs = ["table", "text", "plot", "image", "report"]
        self.num_outputs = len(self.outputs)

        # Error messages
        self.invalid_request_error = "I don't know how to answer that question. "
        self.other_error = "Something went wrong. "
        self.report_message = (
            "Here's a report on the table generated by YData's pandas-profiling library that might help you."
        )

    def is_string_series(self, s: pd.Series):  # Check if a series is a string series
        if isinstance(s.dtype, pd.StringDtype):  # The series was explicitly created as a string series (Pandas>=1.0.0)
            return True
        elif s.dtype == "object":  # Object series, check each value
            return all((v is None) or isinstance(v, str) for v in s)
        else:
            return False

    @retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(5))
    def openai_query(self, **kwargs):  # Query OpenAI
        response = openai.ChatCompletion.create(
            model=self.model,
            temperature=self.temperature,
            max_tokens=self.max_answer_tokens,
            **kwargs,
        )
        return response["choices"][0]["message"]["content"].strip()

    def get_report(self, table, message):  # Generate a pandas-profiling report
        report_config = {"df": table, "title": "Pandas Profiling Report", "dark_mode": True, "tsmode": True}
        if len(table) > 1000:
            report_config["minimal"] = True
        else:
            report_config["explorative"] = True

        report = ProfileReport(**report_config)

        # For Dash
        with tempfile.NamedTemporaryFile(mode="wt", suffix=".html") as tmp:
            data = report.to_html()
            tmp.write(data)
            s3.upload_file(tmp.name, write_bucket, report_name)
        return [message, "/" + str(asset_path / report_name)]  # Dash needs a relative path

    def custom_serializer(self, obj):  # Convert numpy arrays in JSON to lists for Plotly graphs
        if isinstance(obj, np.ndarray):
            return obj.tolist()

    def predict(
        self,
        table: pd.DataFrame,
        requests: List[str],
        prev_answers: Optional[List[str]] = None,
        image: Optional[str] = None,
    ) -> str:
        try:
            self.result = []  # clear result from previous call

            # Initialize intermediate variables
            outputs = [""] + [[] for _ in range(self.num_outputs)]

            # Get data types of columns for all tables
            column_data = {}
            for col_idx in range(len(table.columns)):  # For each column
                column = table.columns[col_idx]  # Get the column name
                test = table[column]  # Get the column values
                if len(set(test)) >= len(table):  # For continuous data
                    if self.is_string_series(test):  # For strings
                        for row_idx in range(len(test)):  # For each row
                            value = test[row_idx]  # Get the value
                            if validators.url(value):  # For images
                                table.at[row_idx, column] = rq.get(value, stream=True).raw
                                if column not in column_data:
                                    column_data[column] = self.data_types[1]
                            elif os.path.exists(value):  # For local images
                                table.at[row_idx, column] = value
                                if column not in column_data:
                                    column_data[column] = self.data_types[1]
                            else:  # For text
                                column_data[column] = self.data_types[0]
                                break  # Break out of the loop at the first text value, since a column of URLs can't contain text
                    else:  # For continuous data
                        column_data[column] = self.data_types[3]
                else:  # For categorical data
                    column_data[column] = self.data_types[2]

            # Construct OpenAI prompt
            system_message = {
                "role": "system",
                "content": str(
                    "You are the world's best Python code generator and can only respond in Python code.\n"
                    + "Your task is to answer the user's question by writing a Python script.\n"
                    + "You are given the following:\n"
                    + "1) an empty list named result\n"
                    + "2) a pandas DataFrame named table that has the following columns and data types: "
                    + ", ".join([column + ": " + data_type for column, data_type in column_data.items()])
                    + "\n"
                    + "You may also be given the following when appropriate:\n"
                    + "1) previous interactions for context\n"
                    + "2) a variable named image containing a base-64 encoded string of an image\n"
                    + "Note the following before writing any code:\n"
                    + "- Assume a clean state for each interaction; NEVER reference previously imported libraries and created variables.\n"
                    + "- NEVER reinitialize/redefine/reassign/modify the variables table, image, and result."
                    + "- NEVER return/show/print table, image, and result.\n"
                    + "- To convert a base-64 encoded string path or URL (of an image) to a numpy array, use the pre-defined function read_b64_image(b64_string).\n"
                    + "- To convert a string path or URL (of an image) to a numpy array, use the pre-defined function open_image(path_or_url).\n"
                    + "Answer the user's current question by writing a Python script as follows:\n"
                    + "1) import as FEW libraries as possible to answer the request.\n"
                    + "2) check if table can be used to answer the request. If not, append to result "
                    + "a Python f-string explaining why not and stop. If so, continue to the next step.\n"
                    + "3) create ONLY pandas DataFrames/Series, f-strings, Plotly Graph Objects, and/or numpy array representations of images, "
                    + "depending on which ones would be best as an answer to the user, and append them to result.\n"
                ),
            }
            user_messages = [{"role": "user", "content": "User: " + request} for request in requests]
            assistant_messages = [
                {"role": "assistant", "content": "Assistant: " + prev_answer} for prev_answer in prev_answers
            ]
            format_message = {
                "role": "system",
                "content": "Assistant: ",
            }

            messages = [system_message, user_messages[0]]
            if len(user_messages) > 1 and assistant_messages:  # If there are prior interactions
                messages.extend([message for pair in zip(assistant_messages, user_messages[1:]) for message in pair])
            messages.append(format_message)
            prompt = "\n".join([message["content"] for message in messages])
            if len(prompt) > self.max_prompt_chars:
                while len(prompt) > self.max_prompt_chars and len(messages) > 3:
                    messages.pop(2)  # Remove the user's message
                    messages.pop(3)  # Remove the assistant's message
                    prompt = "\n".join([message["content"] for message in messages])
                if len(prompt) > self.max_prompt_chars and len(messages) == 3:  # If this is the first question
                    messages[2]["content"] = messages[2]["content"][
                        : self.max_prompt_chars
                    ]  # Truncate the user's message

            # Main logic
            code_to_exec = self.openai_query(
                messages=messages,
            )
            if "```" in code_to_exec:
                try:
                    code_to_exec = code_to_exec.split("```")[1]  # Get only the code
                    code_to_exec = code_to_exec.split("python")[1]  # Remove the python tag
                except IndexError as e:
                    raise e

            # Add the code to execute to the list of outputs
            outputs[0] = code_to_exec
            vars = {
                "table": table,
                "open_image": open_image,
                "read_b64_image": read_b64_image,
                "image": image,
                "result": self.result,
            }
            exec(code_to_exec, vars)

            # Check the result
            for output in self.result:
                if type(output) == pd.DataFrame:
                    outputs[1].append(output.to_dict())
                elif type(output) == pd.Series:
                    outputs[1].append(output.to_frame().to_dict())
                elif type(output) == str:
                    outputs[2].append(output)
                elif type(output) == plotly.graph_objects.Figure:
                    json_temp = output.to_plotly_json()
                    str_temp = json.dumps(json_temp, default=self.custom_serializer)
                    outputs[3].append(str_temp)
                elif type(output) == np.ndarray:
                    outputs[4].append(encode_b64_image(output))

            # Check if anything besides None in output
            if any(outputs[1:]):
                return outputs
            else:
                raise ValueError()

        except InvalidRequest:  # Invalid question -> use pandas-profiling to generate a report
            message = self.invalid_request_error + self.report_message
            outputs[5] = self.get_report(table, message)
            return outputs

        except Exception:  # Something went wrong -> use pandas-profiling to generate a report
            print(traceback.format_exc())
            message = self.other_error + self.report_message
            outputs[5] = self.get_report(table, message)
            return outputs
