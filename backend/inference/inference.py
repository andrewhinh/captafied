# Imports
import json
import math
import os
from pathlib import Path
import re
import tempfile
import traceback
from typing import List, Optional

from backend.util import encode_b64_image, open_image, read_b64_image
import boto3
from botocore import UNSIGNED
from botocore.config import Config
from dotenv import load_dotenv
import numpy as np
import openai
import pandas as pd
import plotly
import plotly.io as pio
import requests as rq
from tenacity import retry, stop_after_attempt, wait_random_exponential
import tiktoken
import validators
from ydata_profiling import ProfileReport

# Setup
load_dotenv()

pio.templates.default = "plotly_dark"
openai.api_key = os.getenv("OPENAI_API_KEY")

write_bucket = "captafied-ydata-report"
asset_path = Path("assets")
report_name = "report.html"
s3 = boto3.client("s3", config=Config(signature_version=UNSIGNED))


# Classes
class Pipeline:
    """
    Main inference class
    """

    wait_min = 1  # Minimum wait time in seconds
    wait_max = 60  # Maximum wait time in seconds
    max_attempts = 3  # Maximum number of attempts to retry

    def __init__(self):
        # Data types
        self.data_types = [
            "text string",
            "string URL to an image (not base-64 encoded)",
            "string file path to an image (not base-64 encoded)",
            "categorical",
            "continuous",
        ]  # Context for system message

        # OpenAI params
        self.model = "gpt-4-vision-preview"
        self.encoder = tiktoken.encoding_for_model(self.model)
        self.max_tokens = 128000
        self.max_output_tokens = 4096
        self.temperature = 0.0
        self.detail = "high"  # https://platform.openai.com/docs/guides/vision/low-or-high-fidelity-image-understanding

        self.max_input_tokens = int(self.max_tokens - self.max_output_tokens)
        self.num_exec_retries = 3  # Number of times for the agent to retry executing the code

        # Outputs
        self.result = []
        self.outputs = ["table", "text", "plot", "image", "report"]
        self.num_outputs = len(self.outputs)

        # Error messages
        self.other_error = "Something went wrong. "
        self.report_message = (
            "Here's a report on the table generated by YData's pandas-profiling library that might help you."
        )

    def is_string_series(self, s: pd.Series):  # Check if a series is a string series
        if isinstance(s.dtype, pd.StringDtype):  # The series was explicitly created as a string series (Pandas>=1.0.0)
            return True
        elif s.dtype == "object":  # Object series, check each value
            return all((v is None) or isinstance(v, str) for v in s)
        else:
            return False

    def count_image_tokens(self, image: np.ndarray) -> int:  # Count the number of tokens in an image
        # https://platform.openai.com/docs/guides/vision/calculating-costs
        # Get the dimensions of the image
        height, width = image.shape[:2]

        # Scale down to fit within a 2048 square if needed
        if max(width, height) > 2048:
            scale_factor = 2048 / max(width, height)
            width, height = int(width * scale_factor), int(height * scale_factor)

        # Further scale down to make the shortest side 768px long
        scale_factor = 768 / min(width, height)
        width, height = int(width * scale_factor), int(height * scale_factor)

        # Calculate the number of 512px tiles needed
        tiles_width = math.ceil(width / 512)
        tiles_height = math.ceil(height / 512)
        total_tiles = tiles_width * tiles_height

        # Calculate the cost for this image
        return total_tiles * 170 + 85

    def count_text_tokens(self, text: str) -> int:  # Count the number of tokens in a string
        # https://platform.openai.com/docs/guides/vision/calculating-costs
        return len(self.encoder.encode(text))

    def count_tokens(self, messages: List[str]) -> int:  # Count the number of tokens in a list of messages
        # https://platform.openai.com/docs/guides/vision/calculating-costs
        text = "\n".join([message["content"][0]["text"] for message in messages])
        text_tokens = self.count_text_tokens(text)

        images = []
        for message in messages:
            if len(message["content"]) > 1:
                images.append(message["content"][1]["image_url"]["url"])
        images = np.array([read_b64_image(image) for image in images])
        image_tokens = 0
        if self.detail == "high":
            for image in images:
                image_tokens += self.count_image_tokens(image)
        else:
            image_tokens = 85 * len(images)  # 85 tokens per image

        return image_tokens + text_tokens

    @retry(wait=wait_random_exponential(min=wait_min, max=wait_max), stop=stop_after_attempt(max_attempts))
    def openai_query(self, **kwargs):  # Query OpenAI
        response = openai.ChatCompletion.create(
            model=self.model,
            temperature=self.temperature,
            max_tokens=self.max_output_tokens,
            **kwargs,
        )
        return response.choices[0].message.content

    def run_agent_loop(self, table, messages):
        vars = {
            "table": table,
            "open_image": open_image,
            "read_b64_image": read_b64_image,
            "result": self.result,
        }
        try:
            code_to_exec = self.openai_query(
                messages=messages,
            )
            code_to_exec = self.sanitize_exec_code(code_to_exec)
            exec(code_to_exec, vars)
            return code_to_exec
        except Exception:
            print(traceback.format_exc())
            if self.num_exec_retries == 0:
                return None
            self.num_exec_retries -= 1
            system_message = {
                "role": "system",
                "content": [
                    {
                        "type": "text",
                        "text": str(
                            "Your code failed to execute. This is the error message:\n"
                            + traceback.format_exc()
                            + "You have "
                            + str(self.num_exec_retries)
                            + " attempts left."
                        ),
                    }
                ],
            }
            messages.append(system_message)
            return self.run_agent_loop(table, messages)

    def sanitize_exec_code(self, query: str) -> str:
        # Removes `, whitespace & python from start
        query = re.sub(r"^(\s|`)*(?i:python)?\s*", "", query)
        # Removes whitespace & ` from end
        query = re.sub(r"(\s|`)*$", "", query)
        return query

    def get_report(self, table, message):  # Generate a pandas-profiling report
        report_config = {"df": table, "title": "Pandas Profiling Report", "dark_mode": True, "tsmode": True}
        if len(table) > 1000:
            report_config["minimal"] = True
        else:
            report_config["explorative"] = True

        report = ProfileReport(**report_config)

        # For Dash
        with tempfile.NamedTemporaryFile(mode="wt", suffix=".html") as tmp:
            data = report.to_html()
            tmp.write(data)
            s3.upload_file(tmp.name, write_bucket, report_name)
        return [message, "/" + str(asset_path / report_name)]  # Dash needs a relative path

    def custom_serializer(self, obj):  # Convert numpy arrays in JSON to lists for Plotly graphs
        if isinstance(obj, np.ndarray):
            return obj.tolist()

    def predict(
        self,
        table: pd.DataFrame,
        requests: List[dict],
        prev_answers: Optional[List[str]] = None,
    ) -> str:
        self.result = []  # clear result from previous call

        # Initialize intermediate variables
        outputs = [""] + [[] for _ in range(self.num_outputs)]

        # Get data types of columns for all tables
        column_data = {}
        for col_idx in range(len(table.columns)):  # For each column
            column = table.columns[col_idx]  # Get the column name
            test = table[column]  # Get the column values
            if len(set(test)) >= len(table):  # For continuous data
                if self.is_string_series(test):  # For strings
                    for row_idx in range(len(test)):  # For each row
                        value = test[row_idx]  # Get the value
                        if validators.url(value):  # For images
                            table.at[row_idx, column] = rq.get(value, stream=True).raw
                            if column not in column_data:
                                column_data[column] = self.data_types[1]
                        elif os.path.exists(value):  # For local images
                            table.at[row_idx, column] = value
                            if column not in column_data:
                                column_data[column] = self.data_types[2]
                        else:  # For text
                            column_data[column] = self.data_types[0]
                            break  # Break out of the loop at the first text value, since a column of URLs can't contain text
                else:  # For continuous data
                    column_data[column] = self.data_types[4]
            else:  # For categorical data
                column_data[column] = self.data_types[3]

        # Construct OpenAI prompt
        system_message = {
            "role": "system",
            "content": [
                {
                    "type": "text",
                    "text": str(
                        "You are the world's best Python code generator and can only respond in Python code.\n"
                        + "Your task is to answer the user's question by writing a Python script.\n"
                        + "You are given the following:\n"
                        + "1) an empty list named result\n"
                        + "2) a pandas DataFrame named table that has the following columns and data types: "
                        + ", ".join([column + ": " + data_type for column, data_type in column_data.items()])
                        + "\n"
                        + "When appropriate, you may also be given the following:\n"
                        + "1) previous interactions for context\n"
                        + "2) an image relevant to the user's question\n"
                        + "Besides the Python Standard Libraries, these are the ONLY libraries you can import:\n"
                        + "- numpy as np\n"
                        + "- pandas as pd\n"
                        + "- plotly\n"
                        + "- plotly.io as pio\n"
                        + "- requests as rq\n"
                        + "- tenacity\n"
                        + "- tiktoken\n"
                        + "- validators\n"
                        + "- ydata_profiling.ProfileReport\n"
                        + "Note the following before writing any code:\n"
                        + "- Assume a clean state for each interaction; NEVER reference previously imported libraries and created variables.\n"
                        + "- NEVER reinitialize/redefine/reassign/modify the variables table and/or result."
                        + "- NEVER return/show/print table and/or result.\n"
                        + "- To convert a base-64 encoded string path or URL (of an image) to a numpy array, use the pre-defined function read_b64_image(b64_string).\n"
                        + "- To convert a string path or URL (of an image) to a numpy array, use the pre-defined function open_image(path_or_url).\n"
                        + "Answer the user's current question by writing a Python script as follows:\n"
                        + "1) Import any  libraries as possible to answer the request.\n"
                        + "2) Check if table can be used to answer the request. If not, append to result "
                        + "a Python f-string explaining why not and stop. If so, continue to the next step.\n"
                        + "3) create ONLY pandas DataFrames/Series, f-strings, Plotly Graph Objects, and/or numpy array representations of images, "
                        + "depending on which ones would be best as an answer to the user, and append them to result.\n"
                    ),
                }
            ],
        }

        # Format messages
        user_messages = []
        for request in requests:
            user_messages.append(
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": request["text"],
                        },
                    ],
                }
            )
            if request["image"]:
                user_messages[-1]["content"].append(
                    {
                        "type": "image_url",
                        "image_url": {"url": request["image"], "detail": self.detail},
                    }
                )
        assistant_messages = [
            {"role": "assistant", "content": [{"type": "text", "text": prev_answer}]} for prev_answer in prev_answers
        ]
        messages = [system_message, user_messages[0]]
        if len(user_messages) > 1 and assistant_messages:  # If there are prior interactions
            messages.extend([message for pair in zip(assistant_messages, user_messages[1:]) for message in pair])

        # Ensure prompt is not too long
        num_tokens = self.count_tokens(messages)
        if num_tokens > self.max_input_tokens:  # If the prompt is too long
            while num_tokens > self.max_input_tokens and len(messages) > 3:
                messages.pop(2)  # Remove the user's message
                messages.pop(3)  # Remove the assistant's message
                num_tokens = self.count_tokens(messages)
            if num_tokens > self.max_input_tokens and len(messages) == 3:  # If this is the first question
                user_message = messages[2]["content"][0]["text"]
                truncated_message = self.encoder.decode(
                    self.encoder.encode(user_message)[: -num_tokens + self.max_input_tokens]
                )  # Truncate the text
                messages[2]["content"][0]["text"] = truncated_message

        # Main logic
        code_to_exec = self.run_agent_loop(table, messages)
        if code_to_exec:  # If the agent successfully executed the code
            # Add the code to execute to the list of outputs
            outputs[0] = code_to_exec

            # Add result to outputs
            for output in self.result:
                if type(output) == pd.DataFrame:
                    outputs[1].append(output.to_dict())
                elif type(output) == pd.Series:
                    outputs[1].append(output.to_frame().to_dict())
                elif type(output) == str:
                    outputs[2].append(output)
                elif type(output) == plotly.graph_objects.Figure:
                    json_temp = output.to_plotly_json()
                    str_temp = json.dumps(json_temp, default=self.custom_serializer)
                    outputs[3].append(str_temp)
                elif type(output) == np.ndarray:
                    outputs[4].append(encode_b64_image(output))
        else:
            message = self.other_error + self.report_message
            outputs[5] = self.get_report(table, message)

        return outputs
