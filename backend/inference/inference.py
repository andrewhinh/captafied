# Imports
import itertools
import os
from os import path
from pathlib import Path
from typing import List, Optional

from dotenv import load_dotenv
from functools import partial
import numpy as np
from onnxruntime import InferenceSession
import openai
import pandas as pd
from pandas_profiling import ProfileReport
from PIL import Image
import plotly
import plotly.express as px
import plotly.graph_objects as go
import plotly.io as pio
from plotly.subplots import make_subplots
import requests as rq
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
import tabula as tb
from transformers import CLIPProcessor
import umap
import validators


# Setup
# Plotly setup
pio.templates.default = "plotly_dark"

# Loading env variables
load_dotenv()

# OpenAI API setup
openai.organization = "org-SenjN6vfnkIealcfn6t9JOJj"
openai.api_key = os.getenv("OPENAI_API_KEY")

# Artifacts (models, etc.) path
parent_path = Path(__file__).resolve().parent
artifact_path = parent_path / "artifacts" / "inference"
onnx_path = artifact_path / "onnx"

# CLIP encoders config
clip_processor = artifact_path / "clip-vit-base-patch16"
clip_onnx = onnx_path / "clip.onnx"


# Classes
class InvalidRequest(ValueError):
    """Raise this when an invalid request is made to the API"""


class Pipeline:
    """
    Main inference class
    """

    def __init__(self):
        # CLIP Setup
        self.clip_session = InferenceSession(str(clip_onnx))
        self.clip_processor = CLIPProcessor.from_pretrained(clip_processor)

        # OpenAI Engine
        self.engine = "text-davinci-003"

        # Graph setup
        self.types = ["text string", "image path/URL", "categorical", "continuous"]

        # Empty return values for both successes and failures
        self.num_output_kinds = 5

        # Error messages
        self.invalid_request_error = "I don't know how to answer that question. "
        self.other_error = "Something went wrong. "
        self.report_message = "Here's a report on the table generated by YData's " \
                              "pandas-profiling library that might help you."

    def is_string_series(self, s: pd.Series):
        if isinstance(s.dtype, pd.StringDtype):
            # The series was explicitly created as a string series (Pandas>=1.0.0)
            return True
        elif s.dtype == "object":
            # Object series, check each value
            return all((v is None) or isinstance(v, str) for v in s)
        else:
            return False

    def openai_query(
        self, prompt, temperature=1.0, max_tokens=16, top_p=1.0, frequency_penalty=0.0, presence_penalty=0.0
    ):
        response = openai.Completion.create(
            engine=self.engine,
            prompt=prompt,
            temperature=temperature,
            max_tokens=max_tokens,
            top_p=top_p,
            frequency_penalty=frequency_penalty,
            presence_penalty=presence_penalty,
        )
        return response["choices"][0]["text"].strip()

    def open_image(self, image):
        image_pil = Image.open(image)
        if image_pil.mode != "RGB":
            image_pil = image_pil.convert("RGB")
        return np.array(image_pil)

    def exec_code(self, table, code):
        global_vars, local_vars = {"self": self, "table": table}, {}
        exec(code, global_vars, local_vars)
        result = local_vars["result"]
        return result

    def get_column_vals(self, table, column, images_present=False):
        if images_present:
            return [self.open_image(image) for image in table[column]]
        else:
            return list(table[column])

    def clip_encode(self, table, text_columns, image_columns):
        # Set up inputs for CLIP
        texts = []
        images = []
        if text_columns:
            for column in text_columns:
                texts.append(self.get_column_vals(table, column))
        if image_columns:
            for column in image_columns:
                images.append(self.get_column_vals(table, column, images_present=True))

        if not texts:
            clip_images = list(itertools.chain.from_iterable(images))
            clip_texts = ["Placeholder value" for _ in range(len(clip_images))]
        elif not images:
            clip_texts = list(itertools.chain.from_iterable(texts))
            clip_images = [np.zeros((224, 224, 3), dtype=np.uint8) for _ in range(len(clip_texts))]
        else:
            clip_texts = list(itertools.chain.from_iterable(texts))
            clip_images = list(itertools.chain.from_iterable(images))
            if len(clip_texts) > len(clip_images):
                clip_images *= len(clip_texts) // len(clip_images)
            elif len(clip_images) > len(clip_texts):
                clip_texts *= len(clip_images) // len(clip_texts)
            else:
                pass

        # CLIP encoding
        inputs = self.clip_processor(text=clip_texts, images=clip_images, return_tensors="np", padding=True)
        clip_outputs = self.clip_session.run(
            output_names=["logits_per_image", "logits_per_text", "text_embeds", "image_embeds"], input_feed=dict(inputs)
        )
        text_embeds = clip_outputs[2]
        image_embeds = clip_outputs[3]

        # Get columns and embeds
        dict_embeds = {}
        if text_columns:
            for column in text_columns:
                dict_embeds[column] = text_embeds[: len(table[column])]
                text_embeds = text_embeds[len(table[column]) :]
        if image_columns:
            for column in image_columns:
                dict_embeds[column] = image_embeds[: len(table[column])]
                image_embeds = image_embeds[len(table[column]) :]

        return dict_embeds

    def get_embeds_graph(self, table, column_data, columns):
        # Separate columns by type
        text_columns = []
        image_columns = []
        cat_columns = []
        cont_columns = []
        for column in columns:
            if column_data[column] in self.types[0]:
                text_columns.append(column)
            elif column_data[column] in self.types[1]:
                image_columns.append(column)
            elif column_data[column] == self.types[2]:
                cat_columns.append(column)
            elif column_data[column] == self.types[3]:
                cont_columns.append(column)
            else:
                pass

        # CLIP embeddings of text and/or images and getting values of any categorical/continuous columns
        dict_embeds = self.clip_encode(table, text_columns, image_columns)
        text_image_columns = list(dict_embeds.keys())
        dict_cat = {}
        dict_cont = {}
        if cat_columns:
            for column in cat_columns:
                dict_cat[column] = self.get_column_vals(table, column)
        if cont_columns:
            for column in cont_columns:
                dict_cont[column] = self.get_column_vals(table, column)

        # Conditionals for plotting
        one_cont_var_present = len(dict_cont) == 1
        two_cont_vars_present = len(dict_cont) == 2
        two_or_more_text_image = len(text_image_columns) > 1

        # Setting up figure
        fig = make_subplots()
        if dict_cont:  # If there are continuous columns, prepare for 3D plot
            list_markers = ["circle", "circle-open", "cross", "diamond", "diamond-open", "square", "square-open", "x"]
        else:
            list_markers = (
                list(range(0, 55))
                + list(range(100, 155))
                + list(range(200, 225))
                + [236]
                + list(range(300, 325))
                + [326]
            )  # https://plotly.com/python/marker-style/#custom-marker-symbols
        markers = itertools.cycle((list_markers))
        color_themes = (
            px.colors.qualitative
        )  # https://plotly.com/python/discrete-color/#color-sequences-in-plotly-express
        list_colors = [getattr(color_themes, att) for att in dir(color_themes)[:-11]]
        colors = list(itertools.chain.from_iterable(list_colors))

        # UMAP and K-Means clustering
        for column, embeds, color in zip(text_image_columns, list(dict_embeds.values()), colors):
            # Legend entries depending on whether there are multiple text/image columns
            prefix = ""
            if two_or_more_text_image:
                prefix = column + ", "

            # Getting # of clusters and K-Means clustering
            range_n_clusters = list(
                range(2, int(len(table) / 2))
            )  # For performance reasons, we don't want to cluster more than half the data
            silhouette_scores = []
            for num_clusters in range_n_clusters:
                # initialise kmeans
                kmeans = KMeans(n_clusters=num_clusters)
                kmeans.fit(embeds)
                labels = kmeans.labels_
                # silhouette score
                silhouette_scores.append(silhouette_score(embeds, labels))
            n_clusters = range_n_clusters[silhouette_scores.index(max(silhouette_scores))]
            kmeans = KMeans(n_clusters=n_clusters, init="k-means++")
            kmeans.fit(embeds)
            clusters = kmeans.labels_

            # Extending added variables to match the number of data points
            if dict_cat:
                for item in dict_cat.items():
                    dict_cat[item[0]] = item[1] * int(len(clusters) / len(item[1]))
            if dict_cont:
                for item in dict_cont.items():
                    dict_cont[item[0]] = item[1] * int(len(clusters) / len(item[1]))

            # Collecting min/max values of continuous variables for axis ranges
            min_x = []
            max_x = []
            min_y = []
            max_y = []
            min_z = []
            max_z = []

            # Reducing dimensionality of embeddings with UMAP
            n_neighbors = 15
            n_components = 2
            if embeds.shape[0] < 15:  # UMAP's default n_neighbors=15, reduce if # of data points is less than 15
                n_neighbors = embeds.shape[0] - 1
            if two_cont_vars_present:  # Reduce UMAP n_components to accomodate for 2 cont variables
                n_components = 1
            reducer = umap.UMAP(n_neighbors=n_neighbors, n_components=n_components)
            embedding = reducer.fit_transform(embeds)
            if n_components == 1:
                x = embedding[:, 0]
                y = None
            else:
                x = embedding[:, 0]
                y = embedding[:, 1]

            # Plotting clusters
            for cluster in range(n_clusters):
                # Getting vars for scatter plot
                marker = next(markers)
                scatter = partial(go.Scatter, mode="markers", marker=dict(symbol=marker, color=color))
                scatter_3d = partial(go.Scatter3d, mode="markers", marker=dict(symbol=marker, color=color))

                # Text/image data
                xs = np.array(x)[clusters == cluster]
                min_x.append(min(xs))
                max_x.append(max(xs))

                if dict_cat and (
                    not dict_cont or one_cont_var_present
                ):  # Only categorical variables or (1 continuous variable and 1+ categorical variables)
                    ys = np.array(y)[clusters == cluster]  # text/image data
                    min_y.append(min(ys))
                    max_y.append(max(ys))
                    if one_cont_var_present:
                        zs = np.array(list(dict_cont.values())[0])[clusters == cluster]
                        min_z.append(min(zs))
                        max_z.append(max(zs))
                    total_cats = [list(np.array(cats)[clusters == cluster]) for cats in list(dict_cat.values())]
                    unique_cats = [np.unique(cats) for cats in total_cats]
                    cat_combinations = list(itertools.product(*unique_cats))
                    total_cats = np.array(total_cats[0])
                    for cat_combination in cat_combinations:
                        name = (
                            prefix
                            + ", ".join(
                                [list(dict_cat.keys())[i] + ": " + str(cat) for i, cat in enumerate(cat_combination)]
                            )
                            + ", "
                            + "Cluster: "
                            + str(cluster)
                        )
                        temp_x = xs[total_cats == cat_combination]
                        temp_y = ys[total_cats == cat_combination]
                        if one_cont_var_present:
                            temp_z = zs[total_cats == cat_combination]
                            fig.add_trace(
                                scatter_3d(
                                    x=temp_x,
                                    y=temp_y,
                                    z=temp_z,
                                    name=name,
                                    marker=dict(symbol=marker, color=color),
                                ),
                            )
                        else:
                            fig.add_trace(
                                scatter(
                                    x=temp_x,
                                    y=temp_y,
                                    name=name,
                                    marker=dict(symbol=marker, color=color),
                                ),
                            )

                        marker = next(markers)

                elif one_cont_var_present:  # Only 1 continuous variable
                    ys = np.array(y)[clusters == cluster]
                    zs = np.array(list(dict_cont.values())[0])[clusters == cluster]
                    min_y.append(min(ys))
                    max_y.append(max(ys))
                    min_z.append(min(zs))
                    max_z.append(max(zs))
                    name = prefix + "Cluster: " + str(cluster)
                    fig.add_trace(scatter_3d(x=xs, y=ys, z=zs, name=name))

                elif two_cont_vars_present:  # Only 2 continuous variables
                    ys = np.array(list(dict_cont.values())[0])[clusters == cluster]
                    zs = np.array(list(dict_cont.values())[1])[clusters == cluster]
                    min_y.append(min(ys))
                    max_y.append(max(ys))
                    min_z.append(min(zs))
                    max_z.append(max(zs))
                    name = prefix + "Cluster: " + str(cluster)
                    fig.add_trace(scatter_3d(x=xs, y=ys, z=zs, name=name))

                else:  # No continuous/categorical variables
                    ys = np.array(y)[clusters == cluster]
                    min_y.append(min(ys))
                    max_y.append(max(ys))
                    name = prefix + "Cluster: " + str(cluster)
                    fig.add_trace(scatter(x=xs, y=ys, name=name))

            # Labelling + setting axis ranges
            if dict_cont:
                # Getting ranges for axis
                x_min = min(min_x)
                x_max = max(max_x)
                if type(x_min) == np.ndarray and type(x_max) == np.ndarray:
                    x_min = x_min[0]
                    x_max = x_max[0]
                y_min = min(min_y)
                y_max = max(max_y)
                z_min = min(min_z)
                z_max = max(max_z)

                # Setting axis ranges
                if one_cont_var_present:
                    fig.update_layout(
                        scene=dict(
                            xaxis=dict(
                                range=[x_min, x_max],
                            ),
                            yaxis=dict(
                                range=[y_min, y_max],
                            ),
                            zaxis=dict(
                                title=list(dict_cont.keys())[0],
                                range=[z_min, z_max],
                            ),
                        )
                    )
                elif two_cont_vars_present:
                    fig.update_layout(
                        scene=dict(
                            xaxis=dict(
                                range=[x_min, x_max],
                            ),
                            yaxis=dict(
                                title=list(dict_cont.keys())[0],
                                range=[y_min, y_max],
                            ),
                            zaxis=dict(
                                title=list(dict_cont.keys())[1],
                                range=[z_min, z_max],
                            ),
                        )
                    )

        """
        # HDBSCAN clustering
        import hdbscan
        
        offset = 0 # To label the clusters in a continuous manner
        for embeds, color in zip(list_embeds, colors):
            # Reducing dimensionality of embeddings with UMAP
            reducer = umap.UMAP()
            embedding = reducer.fit_transform(embeds)
            x = embedding[:, 0]
            y = embedding[:, 1]

            clusters = hdbscan.HDBSCAN().fit_predict(embedding)
            clustered = (clusters >= 0)
            n_clusters = max(clusters) + 1

            clustered_x = embedding[clustered, 0]
            clustered_y = embedding[clustered, 1]
            unclustered_x = embedding[~clustered, 0]
            unclustered_y = embedding[~clustered, 1]
            groups = [[clustered_x, clustered_y], [unclustered_x, unclustered_y]]

            # Plotting clusters and unclustered points
            for group_idx in range(len(groups)):
                group = groups[group_idx]
                for cluster in range(n_clusters):
                    # Plotting points
                    xs = np.array(group[0])[clusters == cluster]
                    ys = np.array(group[1])[clusters == cluster]
                    if group_idx < len(groups) - 1:
                        # Using same marker for all unclustered points
                        marker = "."
                        # Adding cluster to legend if applicable
                        artist = matplotlib.lines.Line2D([], [], color=color, lw=0, marker=marker)
                        handles.append(artist)
                        labels.append(str(cluster + offset))
                    else:
                        marker = next(markers)
                    ax.scatter(xs, ys, color=color, marker=marker, alpha=1)
        
            # To label the clusters in a continuous manner
            if len(list_embeds) > 1:
                offset += n_clusters 
        
        # Legend for clusters
        legend = ax.legend(handles, labels, loc="upper right", title="Clusters")
        ax.add_artist(legend)
            
        # Adding legend for image and text groups
        if len(list_embeds) > 1: 
            handles = []
            labels = []           
            for color, type in zip(colors, self.types):
                artist = matplotlib.lines.Line2D([], [], color=color, lw=0, marker="o")
                handles.append(artist)
                labels.append(type[0].upper() + type[1:])
            ax.legend(handles, labels, loc="lower left", title="Data Types")
        """

        # Titles
        variables = text_image_columns + list(dict_cat.keys()) + list(dict_cont.keys())
        variables = [variable + " Embedding Clusters" if variable in dict_embeds.keys() else variable for variable in variables]
        variables = " vs. ".join(variables)
        legend_titles = ["Embedding Clusters", "Columns", "Categories"]
        if two_or_more_text_image and dict_cat:  # 2 or more text/image columns and 1 or more categorical columns
            legend_title = ", ".join(legend_titles)
        elif two_or_more_text_image:  # 2 or more text/image columns
            legend_title = " and ".join(legend_titles[:2])
        elif dict_cat:  # 1 or more categorical columns
            legend_title = " and ".join([legend_titles[0], legend_titles[2]])
        else:  # No categorical columns and 1 text/image column
            legend_title = legend_titles[0]
        fig.update_layout(
            title={"text": variables, "y": 0.9, "x": 0.5, "xanchor": "center", "yanchor": "top"},
            legend={"title": legend_title, "y": 0.9, "x": 0.9, "xanchor": "right", "yanchor": "top"},
        )

        return [fig, variables + " Plotly Graph Object"]

    def get_report(self, table, message):
        if len(table) > 1000:
            report = ProfileReport(table, title="Pandas Profiling Report", minimal=True)
        else:
            report = ProfileReport(table, title="Pandas Profiling Report", explorative=True)

        # For Dash
        report_path = Path("assets") / "report.html"
        full_report_path = parent_path / ".." / ".." / "frontend" / report_path
        report.to_file(full_report_path)
        return [message, "/" + str(report_path)]

    def predict(
        self, 
        table: pd.DataFrame, 
        requests: List[str],
        prev_answers: Optional[List[str]] = None,
    ) -> str: # Type handling is done by frontend
        # Setting empty outputs list to be filled with results
        outputs = [None] * self.num_output_kinds
    
        # Getting data types of columns for all tables
        column_data = {}
        for col_idx in range(len(table.columns)):  # For each column
            column = table.columns[col_idx]  # Get the column name
            test = table[column]  # Get the column values
            if len(set(test)) >= len(table):  # For continuous data
                if self.is_string_series(test):  # For strings
                    for row_idx in range(len(test)):  # For each row
                        value = test[row_idx]  # Get the value
                        potential_path = str(parent_path / value)  # Get the potential path
                        if validators.url(value):  # For images
                            table.at[row_idx, column] = rq.get(value, stream=True).raw
                            if not column in column_data:
                                column_data[column] = self.types[1]
                        elif path.exists(potential_path):  # For local images
                            table.at[row_idx, column] = potential_path
                            if not column in column_data:
                                column_data[column] = self.types[1]
                        else:  # For text
                            column_data[column] = self.types[0]
                            break  # Break out of the loop at the first text value
                else:  # For continuous data
                    column_data[column] = self.types[3]
            else:  # For categorical data
                column_data[column] = self.types[2]

        # Converting lists to strings
        str_info = ", ".join([column + ": " + data_type for column, data_type in column_data.items()])

        # Introduction for every OpenAI prompt
        intro = str("You are given a Python pandas DataFrame named table. "
                    + "You are also given a comma-separated list that contains "
                    + "pairs of table's columns and corresponding data types: "
                    + str_info + "\nRegarding table, a user ")

        # Structure the introduction based on the number of previous requests
        if prev_answers: # If there are previous requests
            intro += "asked: " + requests[0] + "\n"
            for idx, (request, prev_answer) in enumerate(zip(requests[1:], prev_answers)):
                intro += "You answered: " + prev_answer + "\nThen, a user "
                if idx < len(requests) - 1: # If there are more requests
                    intro += "asked: " + request + "\n"
                else: # If this is the most recent one
                    intro += "asks: " + request + "\n"
            intro += "Take into account the previous requests and answers.\n"
        else: # If there are no previous requests
            intro += "asks: " + requests[0] + "\n"

        # Get the user's request type
        which_answers = self.openai_query(
            prompt=intro
            + "If the user is asking for whole pandas DataFrame operations or a modification of table " \
            + "rather than a lookup, which would require a pandas DataFrame as an output, return '1'.\n"
            + "If the user is asking for a column/row-wise lookup, meaning that they are "
            + "asking for entire column(s)/row(s) that satisfy some condition and "
            + "would require a pandas DataFrame as an output, return '2'.\n"
            + "If the user is asking for a cell-wise lookup or calculation, meaning "
            + "that they are asking for a single value that can be found in/calcaluated "
            + "from table and satisfies some condition, and would require a Python string as an output, return '3'.\n"
            + "If the user is asking about a distribution/relationship question without any mention of " 
            + "embeddings or clusters, meaning they are asking about a pattern within table, and "
            + "would require a Plotly graph as an output, return '4'.\n"
            + "If the user is asking about a distribution/relationship question with a mention of "
            + "embeddings or clusters, meaning they are asking about a pattern within table, "
            + "and would require a Plotly graph as an output, return '5'.\n"
            + "Some notes about the above:\n"
            + "1. If the user's request belongs to more than one of the above, return all numbers separated by commas.\n"
            + "2. If the user's request is not one of the above, return '0': ",
            temperature=0,
            max_tokens=10,
        )

        try:  # For valid questions
            # Converting to list or int
            if "," in which_answers:  # For multiple answers
                which_answers = which_answers.split(",")
                which_answers = [int(item) for item in which_answers]
            else:
                which_answers = [int(which_answers)]
            
            # Intro prompt phrase
            intro += "Write minimal, uncommented Python code that "

            # Define notes for OpenAI prompt
            note = str("Some notes about writing the code:\n"
                        + "1. Don't call 'print' or 'return'.\n"
                        + "2. Don't import anything.\n"
                        + "3. Whenever you call 'len()' or slice a pandas DataFrame, understand what it will return.\n"
                        + "4. Avoid creating functions or classes unless necessary, in which case they must be called "
                        + "within the code.\n"
                        + "5. As necessary, call 'self.open_image()', which takes a string path to an image as an argument "
                        + "and returns the image as a Python numpy array, either directly on an string path or as a mapped "
                        + "function over a list or pandas Series.\n"
                        + "6. If the user is asking a question that cannot be answered with the information found in table, "
                        + "return 'raise InvalidRequest()'. ")

            # Table modifications
            if 1 in which_answers:
                code_to_exec = self.openai_query(
                    prompt=intro
                    + "creates a copy of table to modify while retaining table itself and assigns the copy to result.\n"
                    + note,
                    temperature=0.1,
                    max_tokens=100,
                )
                answer = [self.exec_code(table, code_to_exec), code_to_exec]
                if type(answer[0]) == pd.DataFrame:
                    outputs[0] = answer
                else:
                    raise ValueError

            # Table row-wise lookups/reasoning questions
            if 2 in which_answers:
                code_to_exec = self.openai_query(
                    prompt=intro
                    + "creates a copy of table to slice by row/column while retaining table itself and assigns the sliced copy to result.\n"
                    + note,
                    temperature=0.1,
                    max_tokens=100,
                )
                answer = [self.exec_code(table, code_to_exec), code_to_exec]
                if type(answer[0]) == pd.DataFrame:
                    outputs[0] = answer
                else:
                    raise ValueError

            # Table cell-wise lookups/reasoning questions
            if 3 in which_answers:
                code_to_exec = self.openai_query(
                    prompt=intro
                    + "to answer the user's request, first finds relevant information from table, then "
                    + "generates an f-string that uses the information as an answer and assigns it to result.\n"
                    + note,
                    temperature=0.1,
                    max_tokens=250,
                )
                answer = [self.exec_code(table, code_to_exec).strip('"'), code_to_exec]
                if type(answer[0]) == str:
                    outputs[1] = answer
                else:
                    raise ValueError

            # Distribution/relationship questions without text or image clusters
            if 4 in which_answers:
                code_to_exec = self.openai_query(
                    prompt=intro
                    + "draws an appropriate graph with Python's Plotly package. Make sure that it:\n"
                    + "1. Creates a variable figure that is a plotly.graph_objects.Figure object "
                    + "and assigns the graph to it.\n"
                    + "2. Labels the graph's (centered) title, axes, and legend as necessary.\n"
                    + "3. Assigns the variable figure to result.\n"
                    + note,
                    temperature=0.1,
                    max_tokens=250,
                )
                answer = [self.exec_code(table, code_to_exec), code_to_exec]
                if type(answer[0]) == plotly.graph_objects.Figure:
                    outputs[2] = answer
                else:
                    raise ValueError

            # Questions involving text and/or image embeddings/clusters
            if 5 in which_answers:
                str_columns = self.openai_query(
                    prompt=intro
                    + "List the columns mentioned in the user's current request that are necessary to generate a graph to "
                    + "answer the user as a comma-separated list. Some notes:\n"
                    + "1. If a mentioned column has the words 'embeddings' or 'clusters' after it, "
                    + "it is most likely a text or image column and needs to be included.\n"
                    + "2. If you think a column is necessary but it is phrased in a way that suggests it posseses "
                    + "another column, it should be ignored. For example, if the user asks 'What do the repo's "
                    + "description embeddings look like?' regarding table, the column 'Repos' should be "
                    + "ignored because it posseses the column 'Description', and only the column 'Description' "
                    + "should be used.\n"
                    + "3. If the user is asking to graph more than two categorical and/or continuous columns, "
                    + "return 'None'. ",
                    temperature=0.1,
                    max_tokens=250,
                )
                columns = str_columns.split(", ")
                for column in columns:
                    if column not in table.columns:
                        raise InvalidRequest()
                answer = self.get_embeds_graph(table, column_data, columns)
                if type(answer[0]) == plotly.graph_objects.Figure:
                    outputs[2] = answer
                else:
                    raise ValueError

            # Check if anything besides None in output
            if any(outputs):
                return outputs
            else:
                raise InvalidRequest()

        except InvalidRequest:  # Invalid question -> use pandas-profiling to generate a report
            message = self.invalid_request_error + self.report_message
            outputs[3] = self.get_report(table, message)
            return outputs

        except Exception:  # Something went wrong -> use pandas-profiling to generate a report
            message = self.other_error + self.report_message
            outputs[3] = self.get_report(table, message)
            return outputs